import argparse
import torch
from exp.Train import  Exp_Adapted_Progressive_Battery, setup_progressive_args
import random
import numpy as np
import os
from datetime import datetime

def main():
    # è®¾ç½®éšæœºç§å­
    seed = 2021
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

    parser = argparse.ArgumentParser(description='DualBranch FusedTimeModel')

    args = setup_progressive_args(args)
    # åŸºç¡€é…ç½®
    parser.add_argument('--task_name', type=str, default='long_term_forecast')
    parser.add_argument('--is_training', type=int, default=1)
    parser.add_argument('--model_id', type=str, default='dual_branch_test')
    parser.add_argument('--model', type=str, default='DD',
                        choices=['DualBranchModel', 'FusedTimeModel', 'dual'],
                        help='æ¨¡å‹é€‰æ‹©ï¼šDualBranchModel(åŒåˆ†æ”¯æ—¶é¢‘åŸŸ), FusedTimeModel(åŸèåˆæ¨¡å‹), dual(åŒåˆ†æ”¯ç®€ç§°)')
    ##å°æ³¢å˜æ¢
    parser.add_argument('--wavelet_name', type=str, default='db4',
                        help='Wavelet type for decomposition (db4, db8, haar, coif2, etc.)')
    parser.add_argument('--wavelet_level', type=int, default=3,
                        help='Number of decomposition levels for wavelet transform')
    parser.add_argument('--use_amp', type=int, default=0,
                        help='Whether to use automatic mixed precision for wavelet transform')

    parser.add_argument('--noise_strategy', type=str, default='learnable',
                        choices=['fixed', 'learnable', 'adaptive'],
                        help='å™ªå£°åˆ†é…ç­–ç•¥: fixed(å›ºå®š), learnable(å¯å­¦ä¹ ), adaptive(è‡ªé€‚åº”)')
    # æ•°æ®é…ç½®
    parser.add_argument('--data', type=str, default='Custom')
    parser.add_argument('--root_path', type=str, default='./dataset/')
    parser.add_argument('--data_path', type=str, default='CS2.csv')
    parser.add_argument('--features', type=str, default='MS')
    parser.add_argument('--target', type=str, default='Target')
    parser.add_argument('--freq', type=str, default='h')
    parser.add_argument('--checkpoints', type=str, default='./checkpoints/')
    parser.add_argument('--seasonal_patterns', type=str, default=None, help='seasonal patterns for M4 dataset')

    # é¢„æµ‹ä»»åŠ¡é…ç½®
    parser.add_argument('--seq_len', type=int, default=15)
    parser.add_argument('--label_len', type=int, default=15)
    parser.add_argument('--pred_len', type=int, default=1)

    # æ¨¡å‹é…ç½®
    parser.add_argument('--enc_in', type=int, default=8)
    parser.add_argument('--c_out', type=int, default=1)
    parser.add_argument('--d_model', type=int, default=256, help='æ¨¡å‹ç»´åº¦ï¼Œå¿…é¡»èƒ½è¢«æ³¨æ„åŠ›å¤´æ•°æ•´é™¤')
    parser.add_argument('--d_ff', type=int, default=1024)
    parser.add_argument('--moving_avg', type=int, default=25, help='ç§»åŠ¨å¹³å‡çª—å£ï¼Œå¿…é¡»æ˜¯å¥‡æ•°')
    parser.add_argument('--dropout', type=float, default=0.1)
    parser.add_argument('--embed', type=str, default='timeF')
    parser.add_argument('--channel_independence', type=int, default=0)
    parser.add_argument('--use_norm', type=int, default=1)
    parser.add_argument('--down_sampling_layers', type=int, default=2)
    parser.add_argument('--down_sampling_window', type=int, default=2)
    parser.add_argument('--begin_order', type=int, default=3, help='èµ·å§‹KANé˜¶æ•°')

    parser.add_argument('--denoiser_mask_type', type=str, default='self_only',
                        choices=['self_only', 'causal', 'none'], help='å»å™ªå™¨maskç±»å‹')
    parser.add_argument('--diffusion_time_steps', type=int, default=50, help='æ‰©æ•£æ—¶é—´æ­¥æ•°')
    parser.add_argument('--diffusion_scheduler', type=str, default='cosine',
                        choices=['cosine', 'linear'], help='å™ªå£°è°ƒåº¦å™¨ç±»å‹')

    # ============ åŒåˆ†æ”¯æ¨¡å‹ç‰¹æœ‰é…ç½® ============
    parser.add_argument('--freq_attention_heads', type=int, default=8,
                        help='é¢‘åŸŸåˆ†æ”¯æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--channel_attention_reduction', type=int, default=8,
                        help='é€šé“æ³¨æ„åŠ›reductionæ¯”ä¾‹')
    parser.add_argument('--initial_branch_weight_time', type=float, default=0.4,
                        help='æ—¶åŸŸåˆ†æ”¯åˆå§‹æƒé‡')
    parser.add_argument('--enable_fourier_learning', type=bool, default=False,
                        help='æ˜¯å¦å¯ç”¨é¢‘åŸŸå­¦ä¹ åˆ†æ”¯')
    parser.add_argument('--fourier_modes', type=int, default=32,
                        help='å‚…é‡Œå¶å˜æ¢ä¿ç•™çš„æ¨¡å¼æ•°')

    # ============ ç²¾ç®€ç‰ˆEnhanced STARé…ç½® ============
    parser.add_argument('--use_deformable_conv', type=bool, default=True,
                        help='æ˜¯å¦ä½¿ç”¨å¯å˜å½¢å·ç§¯æ£€æµ‹å®¹é‡å›å‡')
    parser.add_argument('--use_adaptive_loss', type=bool, default=True,
                        help='æ˜¯å¦ä½¿ç”¨Barronè‡ªé€‚åº”æŸå¤±å‡½æ•°')

    # ============ èåˆæƒé‡é…ç½® ============
    parser.add_argument('--trend_weight', type=float, default=0.4,
                        help='è¶‹åŠ¿åˆ†é‡åˆå§‹æƒé‡')
    parser.add_argument('--seasonal_weight', type=float, default=0.2,
                        help='å­£èŠ‚æ€§åˆ†é‡åˆå§‹æƒé‡')
    parser.add_argument('--recovery_weight', type=float, default=0.4,
                        help='å®¹é‡å›å‡åˆ†é‡åˆå§‹æƒé‡')


    # ============ æ‰©æ•£æ¨¡å—é…ç½® ============
    parser.add_argument('--diffusion_steps', type=int, default=100,
                        help='æ‰©æ•£è¿‡ç¨‹çš„æ—¶é—´æ­¥æ•°')
    parser.add_argument('--use_enhanced_diffusion', type=bool, default=True,
                        help='æ˜¯å¦ä½¿ç”¨å¢å¼ºçš„è‡ªé€‚åº”æ‰©æ•£æ¨¡å—')
    parser.add_argument('--use_cross_attention_denoiser', type=bool, default=True,
                        help='æ˜¯å¦åœ¨å­£èŠ‚æ€§åˆ†é‡ä¸­ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›å»å™ªå™¨')

    # ============ èåˆæœºåˆ¶é…ç½® ============
    parser.add_argument('--use_dynamic_fusion', type=bool, default=True,
                        help='æ˜¯å¦ä½¿ç”¨åŠ¨æ€æƒé‡èåˆï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰')
    parser.add_argument('--fusion_type', type=str, default='dynamic',
                        choices=['static', 'dynamic', 'multi_stage'],
                        help='èåˆç±»å‹ï¼šstatic(é™æ€æƒé‡), dynamic(åŠ¨æ€æƒé‡), multi_stage(å¤šé˜¶æ®µèåˆ)')

    # ============ KANå±‚é…ç½® ============
    parser.add_argument('--kan_order_trend', type=int, default=6,
                        help='è¶‹åŠ¿åˆ†é‡KANå±‚çš„é˜¶æ•°')
    parser.add_argument('--kan_order_seasonal', type=int, default=4,
                        help='å­£èŠ‚æ€§åˆ†é‡KANå±‚çš„é˜¶æ•°')
    parser.add_argument('--kan_order_residual', type=int, default=8,
                        help='æ®‹å·®åˆ†é‡KANå±‚çš„é˜¶æ•°')

    # è®­ç»ƒé…ç½®
    parser.add_argument('--num_workers', type=int, default=10)
    parser.add_argument('--itr', type=int, default=1)
    parser.add_argument('--train_epochs', type=int, default=10, help='æœ€å¤§è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--patience', type=int, default=3, help='æ—©åœpatience')
    parser.add_argument('--learning_rate', type=float, default=0.001, help='å­¦ä¹ ç‡')
    parser.add_argument('--des', type=str, default='dual_branch')
    parser.add_argument('--lradj', type=str, default='combined',
                        choices=['type1', 'type2', 'TST', 'adaptive', 'combined', 'plateau'],
                        help='Learning rate adjustment strategy')
    parser.add_argument('--pct_start', type=float, default=0.3)

    # GPUé…ç½®
    parser.add_argument('--use_gpu', type=bool, default=True)
    parser.add_argument('--gpu', type=int, default=0)
    parser.add_argument('--use_multi_gpu', action='store_true', default=False)
    parser.add_argument('--devices', type=str, default='0,1')

    # å®éªŒç®¡ç†é…ç½®
    parser.add_argument('--experiment_name', type=str, default='TSF',
                        help='è‡ªå®šä¹‰å®éªŒåç§°')
    parser.add_argument('--save_detailed_results', type=bool, default=True,
                        help='æ˜¯å¦ä¿å­˜è¯¦ç»†çš„å®éªŒç»“æœ')
    parser.add_argument('--auto_timestamp', type=bool, default=True,
                        help='æ˜¯å¦è‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³')

    args = parser.parse_args()
    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False
    args.device = 'cuda' if args.use_gpu else 'cpu'

    if args.use_gpu and args.use_multi_gpu:
        args.devices = args.devices.replace(' ', '')
        device_ids = args.devices.split(',')
        args.device_ids = [int(id_) for id_ in device_ids]
        args.gpu = args.device_ids[0]

# ============ é…ç½®éªŒè¯å’Œè‡ªåŠ¨è°ƒæ•´ ============
    print("ğŸ”§ éªŒè¯å’Œè°ƒæ•´é…ç½®...")

    # æ ¹æ®èåˆç±»å‹è®¾ç½®åŠ¨æ€èåˆ
    if args.fusion_type == 'dynamic':
        args.use_dynamic_fusion = True
    elif args.fusion_type == 'static':
        args.use_dynamic_fusion = False

    # éªŒè¯æ‰©æ•£é…ç½®
    if args.diffusion_steps <= 0:
        print("âš ï¸  è­¦å‘Šï¼šdiffusion_steps <= 0ï¼Œé‡ç½®ä¸ºé»˜è®¤å€¼ 20")
        args.diffusion_steps = 20

    if args.diffusion_scheduler not in ['cosine', 'linear']:
        print("âš ï¸  è­¦å‘Šï¼šä¸æ”¯æŒçš„è°ƒåº¦å™¨ç±»å‹ï¼Œé‡ç½®ä¸º 'cosine'")
        args.diffusion_scheduler = 'cosine'

    # éªŒè¯KANé˜¶æ•°
    for component in ['trend', 'seasonal', 'residual']:
        order_attr = f'kan_order_{component}'
        order_value = getattr(args, order_attr)
        if order_value < 2:
            print(f"âš ï¸  è­¦å‘Šï¼š{order_attr} < 2ï¼Œé‡ç½®ä¸º 3")
            setattr(args, order_attr, 3)
        elif order_value > 10:
            print(f"âš ï¸  è­¦å‘Šï¼š{order_attr} > 10ï¼Œå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œå»ºè®®é™ä½")


    # æ‰©æ•£é…ç½®ä¿¡æ¯
    print(f'\nğŸŒ€ æ‰©æ•£æ¨¡å—é…ç½®:')
    print(f'   - å¯ç”¨å¢å¼ºæ‰©æ•£: {args.use_enhanced_diffusion}')
    print(f'   - æ‰©æ•£æ­¥æ•°: {args.diffusion_steps}')
    print(f'   - è°ƒåº¦å™¨ç±»å‹: {args.diffusion_scheduler}')
    print(f'   - äº¤å‰æ³¨æ„åŠ›å»å™ª: {args.use_cross_attention_denoiser}')

    # KANé…ç½®ä¿¡æ¯
    print(f'\nğŸ§  KANå±‚é…ç½®:')
    print(f'   - è¶‹åŠ¿åˆ†é‡é˜¶æ•°: {args.kan_order_trend}')
    print(f'   - å­£èŠ‚æ€§åˆ†é‡é˜¶æ•°: {args.kan_order_seasonal}')
    print(f'   - æ®‹å·®åˆ†é‡é˜¶æ•°: {args.kan_order_residual}')

    # èåˆé…ç½®ä¿¡æ¯
    print(f'\nğŸ”— èåˆæœºåˆ¶é…ç½®:')
    print(f'   - èåˆç±»å‹: {args.fusion_type}')
    print(f'   - åŠ¨æ€æƒé‡: {args.use_dynamic_fusion}')

    if args.experiment_name:
        print(f'\nğŸ·ï¸  å®éªŒåç§°: {args.experiment_name}')
    print('=' * 100)

    # è¯¦ç»†å‚æ•°ä¿¡æ¯ï¼ˆå¯é€‰è¾“å‡ºï¼‰
    if args.is_training:
        print('\nğŸ“‹ è¯¦ç»†å‚æ•°é…ç½®:')
        for key, value in sorted(vars(args).items()):
            if key.startswith(('diffusion_', 'kan_', 'denoiser_', 'fusion_', 'use_')):
                print(f'   {key}: {value}')

    print(f'\nğŸ”§ å®Œæ•´å‚æ•°:')
    print(args)

    if args.is_training:
        for ii in range(args.itr):
            # æ„å»ºå®éªŒè®¾ç½®åç§°
            base_setting = f'{args.task_name}_{args.model_id}_{args.model}_{args.data}_sl{args.seq_len}_pl{args.pred_len}_dm{args.d_model}_{args.des}_{ii}'

            # æ·»åŠ æ‰©æ•£é…ç½®åˆ°è®¾ç½®åç§°
            diffusion_suffix = f'_diff{args.diffusion_steps}_{args.diffusion_scheduler}'
            if args.use_dynamic_fusion:
                diffusion_suffix += '_dynfusion'

            if args.experiment_name:
                setting = f'{args.experiment_name}_{base_setting}{diffusion_suffix}'
            else:
                setting = f'{base_setting}{diffusion_suffix}'

            exp = Exp_Adapted_Progressive_Battery(args)
            print(f'\nğŸƒ å¼€å§‹è®­ç»ƒ: {setting}')
            print('>' * 80)
            exp.train(setting)

            print(f'\nğŸ§ª å¼€å§‹æµ‹è¯•: {setting}')
            print('>' * 80)
            exp.test(setting)

            # è¾“å‡ºå®éªŒå®Œæˆä¿¡æ¯
            finish_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print('=' * 100)
            print(f'âœ… å®éªŒå®Œæˆ!')
            print(f'â° å®Œæˆæ—¶é—´: {finish_time}')
            print(f'ğŸ“ ç»“æœæ–‡ä»¶å¤¹: ./results/{setting}_{exp.experiment_timestamp}/')
            print(f'ğŸ“Š æ‰©æ•£é…ç½®: {args.diffusion_steps}æ­¥ + {args.diffusion_scheduler}è°ƒåº¦å™¨')
            print(
                f'ğŸ§  KANé…ç½®: è¶‹åŠ¿{args.kan_order_trend}/å­£èŠ‚{args.kan_order_seasonal}/æ®‹å·®{args.kan_order_residual}é˜¶')
            print(f'ğŸ”— èåˆæ–¹å¼: {args.fusion_type}')
            print('=' * 100)

            torch.cuda.empty_cache()
    else:
        ii = 0
        base_setting = f'{args.task_name}_{args.model_id}_{args.model}_{args.data}_sl{args.seq_len}_pl{args.pred_len}_dm{args.d_model}_{args.des}_{ii}'

        diffusion_suffix = f'_diff{args.diffusion_steps}_{args.diffusion_scheduler}'
        if args.use_dynamic_fusion:
            diffusion_suffix += '_dynfusion'

        if args.experiment_name:
            setting = f'{args.experiment_name}_{base_setting}{diffusion_suffix}'
        else:
            setting = f'{base_setting}{diffusion_suffix}'

        exp = Exp_Fused_Forecast(args)
        print(f'\nğŸ§ª å¼€å§‹æµ‹è¯•: {setting}')
        print('>' * 80)
        exp.test(setting, test=1)

        finish_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print('=' * 100)
        print(f'âœ… æµ‹è¯•å®Œæˆ!')
        print(f'â° å®Œæˆæ—¶é—´: {finish_time}')
        print(f'ğŸ“ ç»“æœæ–‡ä»¶å¤¹: ./results/{setting}_{exp.experiment_timestamp}/')
        print('=' * 100)

        torch.cuda.empty_cache()


if __name__ == '__main__':
    main()