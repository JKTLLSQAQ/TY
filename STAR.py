import torch
import torch.nn as nn
import torch.nn.functional as F
from layers.Autoformer_EncDec import series_decomp
from layers.Embed import DataEmbedding_wo_pos
from layers.StandardNorm import Normalize
from layers.ChebyKANLayer import ChebyKANLinear
from layers.TimeDART_EncDec import Diffusion
from utils.RevIN import RevIN


class EmbeddingSTAR(nn.Module):
    """åœ¨embeddingç©ºé—´åº”ç”¨çš„STARæ¨¡å— - ç®€åŒ–éšæœºæ± åŒ–ç‰ˆæœ¬"""

    def __init__(self, d_model, d_core=None):
        super().__init__()
        self.d_model = d_model
        self.d_core = d_core if d_core is not None else d_model // 2

        # æ ¸å¿ƒè¡¨ç¤ºç”Ÿæˆç½‘ç»œ - å‚è€ƒSOFTSçš„ä¸¤æ­¥è®¾è®¡
        self.gen1 = nn.Linear(d_model, d_model)
        self.gen2 = nn.Linear(d_model, self.d_core)

        # èžåˆç½‘ç»œ - å‚è€ƒSOFTSé£Žæ ¼
        self.gen3 = nn.Linear(d_model + self.d_core, d_model)
        self.gen4 = nn.Linear(d_model, d_model)

    def stochastic_pooling(self, x):
        """SOFTSé£Žæ ¼çš„ç®€åŒ–éšæœºæ± åŒ–"""
        # x: [B, T, d_core]
        batch_size, seq_len, core_dim = x.shape

        if self.training:
            # è®­ç»ƒæ—¶ï¼šæŒ‰æ¦‚çŽ‡éšæœºé‡‡æ · - å‚è€ƒSOFTSçš„ç®€æ´å®žçŽ°
            ratio = F.softmax(x, dim=1)  # [B, T, d_core] - åœ¨æ—¶é—´ç»´åº¦è®¡ç®—æ¦‚çŽ‡
            ratio = ratio.permute(0, 2, 1)  # [B, d_core, T]
            ratio = ratio.reshape(-1, seq_len)  # [B*d_core, T]

            # ä¸ºæ¯ä¸ª(batch, feature)å¯¹é‡‡æ ·ä¸€ä¸ªæ—¶é—´ç‚¹
            indices = torch.multinomial(ratio, 1)  # [B*d_core, 1]
            indices = indices.view(batch_size, core_dim, 1)  # [B, d_core, 1]
            indices = indices.permute(0, 2, 1)  # [B, 1, d_core]

            # æ”¶é›†é‡‡æ ·ç»“æžœ
            core = torch.gather(x, 1, indices)  # [B, 1, d_core]
        else:
            # æµ‹è¯•æ—¶ï¼šåŠ æƒå¹³å‡
            weight = F.softmax(x, dim=1)  # [B, T, d_core]
            core = torch.sum(x * weight, dim=1, keepdim=True)  # [B, 1, d_core]

        return core

    def forward(self, x):
        """
        x: [B, T, d_model] - embeddingåŽçš„ç‰¹å¾
        è¾“å‡º: [B, T, d_model] - å¢žå¼ºåŽçš„ç‰¹å¾
        """
        B, T, D = x.shape

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆä¸­é—´è¡¨ç¤º - å‚è€ƒSOFTS
        combined_mean = F.gelu(self.gen1(x))  # [B, T, d_model]

        # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ ¸å¿ƒè¡¨ç¤ºå€™é€‰
        combined_mean = self.gen2(combined_mean)  # [B, T, d_core]

        # éšæœºæ± åŒ–ç”Ÿæˆå…¨å±€æ ¸å¿ƒ
        global_core = self.stochastic_pooling(combined_mean)  # [B, 1, d_core]

        # å°†å…¨å±€æ ¸å¿ƒåˆ†å‘åˆ°æ¯ä¸ªæ—¶é—´æ­¥
        global_core_expanded = global_core.repeat(1, T, 1)  # [B, T, d_core]

        # èžåˆåŽŸå§‹ç‰¹å¾å’Œå…¨å±€æ ¸å¿ƒ - å‚è€ƒSOFTSçš„fusion
        fused_input = torch.cat([x, global_core_expanded], dim=-1)  # [B, T, d_model + d_core]
        fused_output = F.gelu(self.gen3(fused_input))  # [B, T, d_model]
        fused_output = self.gen4(fused_output)  # [B, T, d_model]

        # æ®‹å·®è¿žæŽ¥
        return fused_output


class SimpleFrequencyProcessor(nn.Module):
    """ç®€å•çš„é¢‘åŸŸå¤„ç†å™¨"""

    def __init__(self, seq_len, pred_len, d_model):
        super().__init__()
        self.seq_len = seq_len
        self.pred_len = pred_len
        self.d_model = d_model

        # è®¡ç®—æœ‰æ•ˆé¢‘çŽ‡ç‚¹
        self.valid_fre_points_in = int((seq_len + 1) / 2 + 0.5)
        self.valid_fre_points_out = int((pred_len + 1) / 2 + 0.5)

        # é¢‘åŸŸç‰¹å¾å¤„ç†ç½‘ç»œ - åˆ†åˆ«å¤„ç†å®žéƒ¨å’Œè™šéƒ¨
        self.freq_processor_real = nn.Sequential(
            nn.Linear(self.valid_fre_points_in, d_model),
            nn.GELU(),
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Linear(d_model, self.valid_fre_points_out)
        )

        self.freq_processor_imag = nn.Sequential(
            nn.Linear(self.valid_fre_points_in, d_model),
            nn.GELU(),
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Linear(d_model, self.valid_fre_points_out)
        )

    def forward(self, x):
        """
        x: [B, T, N] - æ—¶åŸŸè¾“å…¥
        è¾“å‡º: [B, pred_len, N] - é¢‘åŸŸé¢„æµ‹ç»“æžœ
        """
        B, T, N = x.shape

        # è½¬æ¢åˆ°é¢‘åŸŸ - åœ¨æ—¶é—´ç»´åº¦åšFFT
        x_freq = torch.fft.rfft(x, dim=1, norm='ortho')  # [B, valid_fre_points_in, N]

        # åˆ†ç¦»å®žéƒ¨å’Œè™šéƒ¨
        real_part = x_freq.real  # [B, valid_fre_points_in, N]
        imag_part = x_freq.imag  # [B, valid_fre_points_in, N]

        # å¤„ç†æ¯ä¸ªé€šé“çš„é¢‘åŸŸç‰¹å¾
        real_out = []
        imag_out = []

        for i in range(N):
            # å¤„ç†ç¬¬iä¸ªé€šé“
            real_i = self.freq_processor_real(real_part[:, :, i])  # [B, valid_fre_points_out]
            imag_i = self.freq_processor_imag(imag_part[:, :, i])  # [B, valid_fre_points_out]
            real_out.append(real_i)
            imag_out.append(imag_i)

        # é‡æ–°ç»„åˆ
        real_output = torch.stack(real_out, dim=-1)  # [B, valid_fre_points_out, N]
        imag_output = torch.stack(imag_out, dim=-1)  # [B, valid_fre_points_out, N]

        # æž„å»ºå¤æ•°è¾“å‡º
        freq_output = torch.complex(real_output, imag_output)

        # è½¬æ¢å›žæ—¶åŸŸ
        time_output = torch.fft.irfft(freq_output, n=self.pred_len, dim=1, norm='ortho')  # [B, pred_len, N]

        return time_output


class TimeFrquencyFusion(nn.Module):
    """æ—¶é¢‘åŸŸèžåˆæ¨¡å— - ä¿®å¤ç»´åº¦é—®é¢˜"""

    def __init__(self, pred_len, n_channels):
        super().__init__()
        self.pred_len = pred_len
        self.n_channels = n_channels

        # å­¦ä¹ æ—¶é¢‘æƒé‡
        self.time_freq_weights = nn.Parameter(torch.tensor([0.7, 0.3]))  # [time, freq]

        # ðŸ”¥ ä¿®å¤ï¼šé—¨æŽ§æœºåˆ¶ä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
        self.gate = nn.Sequential(
            nn.Linear(2, 1),  # è¾“å…¥æ˜¯2ä¸ªæ ‡é‡ï¼ˆæ—¶åŸŸå€¼å’Œé¢‘åŸŸå€¼ï¼‰ï¼Œè¾“å‡º1ä¸ªæƒé‡
            nn.Sigmoid()
        )

    def forward(self, time_output, freq_output):
        """
        time_output: [B, pred_len, N] - æ—¶åŸŸé¢„æµ‹
        freq_output: [B, pred_len, N] - é¢‘åŸŸé¢„æµ‹
        """
        # æ–¹æ³•1ï¼šç®€å•åŠ æƒèžåˆ
        weights = F.softmax(self.time_freq_weights, dim=0)
        simple_fusion = weights[0] * time_output + weights[1] * freq_output

        # æ–¹æ³•2ï¼šé€ç‚¹è‡ªé€‚åº”é—¨æŽ§èžåˆ
        B, T, N = time_output.shape
        adaptive_outputs = []

        for i in range(N):  # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«å¤„ç†
            time_channel = time_output[:, :, i:i + 1]  # [B, T, 1]
            freq_channel = freq_output[:, :, i:i + 1]  # [B, T, 1]

            # é€æ—¶é—´ç‚¹è®¡ç®—é—¨æŽ§æƒé‡
            channel_outputs = []
            for t in range(T):
                # å–å½“å‰æ—¶é—´ç‚¹çš„å€¼ä½œä¸ºé—¨æŽ§è¾“å…¥
                gate_input = torch.stack([
                    time_channel[:, t, 0],  # [B]
                    freq_channel[:, t, 0]  # [B]
                ], dim=-1)  # [B, 2]

                gate_weight = self.gate(gate_input)  # [B, 1]

                # èžåˆå½“å‰æ—¶é—´ç‚¹
                fused_point = gate_weight * time_channel[:, t:t + 1, :] + (1 - gate_weight) * freq_channel[:, t:t + 1,
                                                                                              :]
                channel_outputs.append(fused_point)

            channel_output = torch.cat(channel_outputs, dim=1)  # [B, T, 1]
            adaptive_outputs.append(channel_output)

        adaptive_fusion = torch.cat(adaptive_outputs, dim=-1)  # [B, T, N]

        # æœ€ç»ˆè¾“å‡ºï¼šç»“åˆä¸¤ç§èžåˆæ–¹å¼
        final_output = 0.5 * simple_fusion + 0.5 * adaptive_fusion

        return final_output


class LightweightDiffusion(nn.Module):
    """è½»é‡çº§æ‰©æ•£æ¨¡å—"""

    def __init__(self, time_steps=20, device='cuda', scheduler='linear'):
        super().__init__()
        self.diffusion = Diffusion(time_steps=time_steps, device=device, scheduler=scheduler)

    def forward(self, x, apply_noise=True):
        if apply_noise and self.training:
            return self.diffusion(x)
        else:
            return x, None, None


class AdaptiveKANMixer(nn.Module):
    """è‡ªé€‚åº”KANæ··åˆå™¨"""

    def __init__(self, d_model, component_type='trend'):
        super().__init__()
        # æ ¹æ®åˆ†é‡ç±»åž‹é€‰æ‹©KANé˜¶æ•°
        order_map = {'trend': 3, 'seasonal': 5, 'residual': 4}
        order = order_map.get(component_type, 4)

        self.kan_layer = ChebyKANLinear(d_model, d_model, order)
        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)
        self.norm = nn.LayerNorm(d_model)

    def forward(self, x):
        B, T, C = x.shape
        x_kan = self.kan_layer(x.reshape(B * T, C)).reshape(B, T, C)
        x_conv = self.conv(x.transpose(1, 2)).transpose(1, 2)
        return self.norm(x + x_kan + x_conv)


class TCNResidualProcessor(nn.Module):
    """TCNæ®‹å·®å¤„ç†å™¨ - ä¸“é—¨ç”¨äºŽå¤„ç†æ®‹å·®åˆ†é‡"""

    def __init__(self, configs, num_levels=4):
        super().__init__()
        self.num_levels = num_levels

        # TCNå‚æ•°
        input_channels = configs.d_model
        hidden_channels = configs.d_model
        kernel_size = 3

        # æž„å»ºå¤šå±‚è†¨èƒ€å·ç§¯
        self.tcn_layers = nn.ModuleList()
        self.residual_layers = nn.ModuleList()

        for i in range(num_levels):
            dilation = 2 ** i  # è†¨èƒ€çŽ‡ï¼š1, 2, 4, 8
            padding = (kernel_size - 1) * dilation

            # å› æžœå·ç§¯å±‚
            conv_layer = nn.Conv1d(
                input_channels,
                hidden_channels,
                kernel_size=kernel_size,
                padding=padding,
                dilation=dilation
            )

            # å±‚å½’ä¸€åŒ–å’Œæ¿€æ´»
            layer_norm = nn.LayerNorm(hidden_channels)
            dropout = nn.Dropout(configs.dropout)

            # æ®‹å·®è¿žæŽ¥çš„1x1å·ç§¯ï¼ˆå¦‚æžœç»´åº¦ä¸åŒ¹é…ï¼‰
            residual_conv = nn.Conv1d(input_channels, hidden_channels, 1) if input_channels != hidden_channels else None

            self.tcn_layers.append(nn.ModuleDict({
                'conv': conv_layer,
                'norm': layer_norm,
                'dropout': dropout
            }))
            self.residual_layers.append(residual_conv)

            input_channels = hidden_channels

        # æœ€ç»ˆè¾“å‡ºå±‚
        self.output_projection = nn.Sequential(
            nn.Linear(hidden_channels, configs.d_ff),
            nn.GELU(),
            nn.Linear(configs.d_ff, configs.d_model),
            nn.Dropout(configs.dropout)
        )

    def forward(self, x):
        """
        x: [B, T, d_model] - è¾“å…¥ç‰¹å¾
        è¾“å‡º: [B, T, d_model] - TCNå¤„ç†åŽçš„ç‰¹å¾
        """
        B, T, C = x.shape

        # è½¬æ¢ä¸ºå·ç§¯æ ¼å¼ [B, C, T]
        x_conv = x.transpose(1, 2)  # [B, d_model, T]

        # é€å±‚TCNå¤„ç†
        for i, (tcn_layer, residual_layer) in enumerate(zip(self.tcn_layers, self.residual_layers)):
            # ä¿å­˜è¾“å…¥ç”¨äºŽæ®‹å·®è¿žæŽ¥
            residual = x_conv

            # å› æžœå·ç§¯
            out = tcn_layer['conv'](x_conv)

            # å› æžœæ€§ï¼šç§»é™¤æœªæ¥ä¿¡æ¯ï¼ˆå³ä¾§paddingï¼‰
            if out.shape[2] > T:
                out = out[:, :, :T]

            # è½¬æ¢å›žæ—¶åºæ ¼å¼è¿›è¡Œå½’ä¸€åŒ–
            out = out.transpose(1, 2)  # [B, T, C]
            out = tcn_layer['norm'](out)
            out = F.gelu(out)
            out = tcn_layer['dropout'](out)
            out = out.transpose(1, 2)  # [B, C, T]

            # æ®‹å·®è¿žæŽ¥
            if residual_layer is not None:
                residual = residual_layer(residual)

            # ç¡®ä¿ç»´åº¦åŒ¹é…
            if residual.shape[2] != out.shape[2]:
                min_len = min(residual.shape[2], out.shape[2])
                residual = residual[:, :, :min_len]
                out = out[:, :, :min_len]

            x_conv = out + residual

        # è½¬æ¢å›žæ—¶åºæ ¼å¼
        x_out = x_conv.transpose(1, 2)  # [B, T, d_model]

        # æœ€ç»ˆæŠ•å½±
        output = self.output_projection(x_out)

        return output


class ComponentProcessor(nn.Module):
    """åˆ†é‡å¤„ç†å™¨ - æ®‹å·®åˆ†é‡ä½¿ç”¨TCN"""

    def __init__(self, configs, component_type):
        super().__init__()
        self.component_type = component_type

        if component_type == 'trend':
            self.processor = nn.Sequential(
                AdaptiveKANMixer(configs.d_model, 'trend'),
                nn.Linear(configs.d_model, configs.d_model),
                nn.GELU(),
                nn.Dropout(configs.dropout)
            )
        elif component_type == 'seasonal':
            # ä¸ºseasonalåˆ†é‡æ·»åŠ ç®€åŒ–çš„STARæ¨¡å—
            self.embedding_star = EmbeddingSTAR(configs.d_model, configs.d_model // 2)
            self.diffusion = LightweightDiffusion(time_steps=20, device=configs.device)
            self.processor = AdaptiveKANMixer(configs.d_model, 'seasonal')
        else:  # residual - ðŸ”¥ ä½¿ç”¨TCNå¤„ç†å™¨
            self.processor = TCNResidualProcessor(configs, num_levels=4)

    def forward(self, x):
        if self.component_type == 'seasonal':
            # å…ˆåº”ç”¨ç®€åŒ–çš„embeddingçº§åˆ«STARæ¨¡å—
            x_star = self.embedding_star(x)

            # ç„¶åŽåº”ç”¨æ‰©æ•£å’Œå¤„ç†
            if self.training:
                x_noise, noise, t = self.diffusion(x_star, apply_noise=True)
                return self.processor(x_noise)
            else:
                return self.processor(x_star)
        else:
            return self.processor(x)


class Model(nn.Module):
    """ç®€å•å¹¶è¡Œæ—¶é¢‘åŒåˆ†æ”¯STARæ¨¡åž‹"""

    def __init__(self, configs):
        super().__init__()
        self.configs = configs
        self.task_name = configs.task_name
        self.seq_len = configs.seq_len
        self.pred_len = configs.pred_len

        # ðŸ”¥ æ—¶åŸŸåˆ†æ”¯ï¼šåŽŸæœ‰çš„STARå¤„ç†æµç¨‹
        self.decomposition = series_decomp(configs.moving_avg)

        # åµŒå…¥å±‚
        if configs.channel_independence == 1:
            self.enc_embedding = DataEmbedding_wo_pos(1, configs.d_model, configs.embed, configs.freq, configs.dropout)
        else:
            self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,
                                                      configs.dropout)

        # æ—¶åŸŸåˆ†é‡å¤„ç†å™¨
        self.trend_processor = ComponentProcessor(configs, 'trend')
        self.seasonal_processor = ComponentProcessor(configs, 'seasonal')
        self.residual_processor = ComponentProcessor(configs, 'residual')

        # æ—¶åŸŸé¢„æµ‹å±‚
        self.trend_predictor = nn.Linear(configs.seq_len, configs.pred_len)
        self.seasonal_predictor = nn.Linear(configs.seq_len, configs.pred_len)
        self.residual_predictor = nn.Linear(configs.seq_len, configs.pred_len)

        # æ—¶åŸŸæŠ•å½±
        if configs.channel_independence == 1:
            self.projection_layer = nn.Linear(configs.d_model, 1, bias=True)
        else:
            self.projection_layer = nn.Linear(configs.d_model, configs.c_out, bias=True)

        # æ—¶åŸŸèžåˆæƒé‡
        self.time_fusion_weights = nn.Parameter(torch.tensor([0.25, 0.5, 0.25]))

        # ðŸ”¥ é¢‘åŸŸåˆ†æ”¯ï¼šç®€å•çš„é¢‘åŸŸå¤„ç†
        self.frequency_processor = SimpleFrequencyProcessor(
            seq_len=configs.seq_len,
            pred_len=configs.pred_len,
            d_model=configs.d_model
        )

        # ðŸ”¥ æ—¶é¢‘èžåˆæ¨¡å—
        self.time_freq_fusion = TimeFrquencyFusion(
            pred_len=configs.pred_len,
            n_channels=configs.c_out
        )

        # å½’ä¸€åŒ–
        self.revin_layer = RevIN(configs.enc_in, affine=True)

    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):
        if self.task_name == 'long_term_forecast':
            return self.forecast(x_enc, x_mark_enc)
        else:
            raise ValueError('Only long_term_forecast implemented')

    def forecast(self, x_enc, x_mark_enc=None):
        B, T, N = x_enc.size()

        # å½’ä¸€åŒ–
        x_enc = self.revin_layer(x_enc, 'norm')

        # ðŸ”¥ æ—¶åŸŸåˆ†æ”¯å¤„ç†
        time_output = self.time_domain_branch(x_enc, x_mark_enc, B, T, N)

        # ðŸ”¥ é¢‘åŸŸåˆ†æ”¯å¤„ç†
        freq_output = self.frequency_processor(x_enc)  # [B, pred_len, N]

        # ðŸ”¥ æ—¶é¢‘èžåˆ
        fused_output = self.time_freq_fusion(time_output, freq_output)

        # åå½’ä¸€åŒ–
        fused_output = self.revin_layer(fused_output, 'denorm')
        return fused_output

    def time_domain_branch(self, x_enc, x_mark_enc, B, T, N):
        """æ—¶åŸŸåˆ†æ”¯å¤„ç†"""
        # åˆ†è§£
        seasonal, trend = self.decomposition(x_enc)
        residual = x_enc - seasonal - trend

        # é€šé“ç‹¬ç«‹æ€§å¤„ç†
        if self.configs.channel_independence == 1:
            seasonal = seasonal.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
            trend = trend.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
            residual = residual.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)

        # åµŒå…¥
        if self.configs.channel_independence == 1 and x_mark_enc is not None:
            x_mark_enc_expanded = x_mark_enc.repeat(N, 1, 1)
        else:
            x_mark_enc_expanded = x_mark_enc

        seasonal_emb = self.enc_embedding(seasonal, x_mark_enc_expanded)
        trend_emb = self.enc_embedding(trend, x_mark_enc_expanded)
        residual_emb = self.enc_embedding(residual, x_mark_enc_expanded)

        # åˆ†é‡å¤„ç†ï¼ˆseasonalåŒ…å«STARæ¨¡å—ï¼‰
        seasonal_out = self.seasonal_processor(seasonal_emb)
        trend_out = self.trend_processor(trend_emb)
        residual_out = self.residual_processor(residual_emb)

        # æ—¶åºé¢„æµ‹
        seasonal_pred = self.seasonal_predictor(seasonal_out.permute(0, 2, 1)).permute(0, 2, 1)
        trend_pred = self.trend_predictor(trend_out.permute(0, 2, 1)).permute(0, 2, 1)
        residual_pred = self.residual_predictor(residual_out.permute(0, 2, 1)).permute(0, 2, 1)

        # æŠ•å½±
        seasonal_pred = self.projection_layer(seasonal_pred)
        trend_pred = self.projection_layer(trend_pred)
        residual_pred = self.projection_layer(residual_pred)

        # æ—¶åŸŸåŠ æƒèžåˆ
        weights = F.softmax(self.time_fusion_weights, dim=0)
        time_output = (weights[0] * trend_pred +
                       weights[1] * seasonal_pred +
                       weights[2] * residual_pred)

        # è¾“å‡ºé‡å¡‘
        if self.configs.channel_independence == 1:
            time_output = time_output.reshape(B, N, self.pred_len, -1)
            if time_output.shape[-1] == 1:
                time_output = time_output.squeeze(-1)
            time_output = time_output.permute(0, 2, 1).contiguous()

        if time_output.shape[-1] > self.configs.c_out:
            time_output = time_output[..., :self.configs.c_out]

        return time_output